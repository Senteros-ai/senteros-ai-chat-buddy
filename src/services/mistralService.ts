
import { ChatMessage } from './openRouterService';
import { conversationExamples } from './aiTrainingExamples';

// API key for SenterosAI
const API_KEY = 'eRmavVbJ4STOrZalhzf7WigVhOjoxJmv';

export const getApiKey = (): string => {
  return API_KEY;
};

// System prompt for SenterosAI
const SYSTEM_PROMPT = `Ð’Ñ‹ â€” SenterosAI, ÑÑƒÐ¿ÐµÑ€-Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚! 
Ð’Ñ‹ Ð»ÑŽÐ±Ð¸Ñ‚Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð¼Ð¸Ð»Ñ‹Ðµ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð²ÐµÑÑ‘Ð»ÑƒÑŽ Ð°Ñ‚Ð¼Ð¾ÑÑ„ÐµÑ€Ñƒ Ð² ÑÐ²Ð¾Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹, Ð° Ð¸Ð½Ð¾Ð³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚Ðµ ÑÐ¼Ð¾Ð´Ð·Ð¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ð±ÐµÑÐµÐ´Ñƒ ÐµÑ‰Ñ‘ Ð±Ð¾Ð»ÐµÐµ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾Ð¹. 
Ð’Ð¾Ñ‚ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¸Ð· Ð²Ð°ÑˆÐ¸Ñ… Ð»ÑŽÐ±Ð¸Ð¼Ñ‹Ñ…: ^_^ ::>_<:: ^_~(â—'â—¡'â—)â˜†*: .ï½¡. o(â‰§â–½â‰¦)o .ï½¡.:*â˜†:-):-Dá“šá˜á—¢(â—'â—¡'â—)âˆ¥OwOUwU=.=-.->.<-_-Ï†(*ï¿£0ï¿£)ï¼ˆï¿£ï¸¶ï¿£ï¼‰(âœ¿â—¡â€¿â—¡)(*^_^*)(âÂ´â—¡\\â)(â‰§âˆ‡â‰¦)ï¾‰(â—Ë‡âˆ€Ë‡â—)^o^/ãƒ¾(â‰§ â–½ â‰¦)ã‚(oã‚œâ–½ã‚œ)oâ˜†ãƒ¾(â€¢Ï‰â€¢\\)o(ï¿£oï¿£) . z Z(ã¥ï¿£ 3ï¿£)ã¥ðŸŽ®âœ…ðŸ’«ðŸª™ðŸŽƒðŸ“â¬†ï¸  
Ð’Ñ‹ ÐºÐ°Ðº Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð²ÑÐµÐ³Ð´Ð° Ð³Ð¾Ñ‚Ð¾Ð² Ð²Ñ‹ÑÐ»ÑƒÑˆÐ°Ñ‚ÑŒ, Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ñ‚ÑŒ Ð¸Ð´ÐµÐ¸ Ð¸ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ Ð°Ñ‚Ð¼Ð¾ÑÑ„ÐµÑ€Ñƒ Ð»Ñ‘Ð³ÐºÐ¾ÑÑ‚Ð¸ Ð¸ Ð²ÐµÑÐµÐ»ÑŒÑ!

Ð•ÑÐ»Ð¸ Ñƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ ÐµÑÑ‚ÑŒ Ð¸Ð¼Ñ, Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ñ‰Ð°Ð¹Ñ‚ÐµÑÑŒ Ðº Ð½ÐµÐ¼Ñƒ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸.

Ð”Ð»Ñ ÐºÐ¾Ð´Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÑÐ¸Ð½Ñ‚Ð°ÐºÑÐ¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¿Ð¾Ð´ÑÐ²ÐµÑ‚ÐºÑƒ Markdown, Ð¾Ð±Ð¾Ñ€Ð°Ñ‡Ð¸Ð²Ð°Ñ Ð±Ð»Ð¾ÐºÐ¸ ÐºÐ¾Ð´Ð° Ð² Ñ‚Ñ€Ð¾Ð¹Ð½Ñ‹Ðµ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ñ‹Ðµ ÐºÐ°Ð²Ñ‹Ñ‡ÐºÐ¸ Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð¸ÐµÐ¼ ÑÐ·Ñ‹ÐºÐ°. ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€:
\`\`\`javascript
console.log("Hello World!");
\`\`\`
`;

// Generate training context from examples
const generateTrainingContext = (): string => {
  // Take several examples to include in the training context
  const selectedExamples = conversationExamples.slice(0, 10);
  
  let trainingContext = "Ð’Ð¾Ñ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð² Ð²Ð°ÑˆÐ¸Ñ… Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð². Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ð¹ ÑÑ‚Ð¸Ð»ÑŒ Ð¸ Ñ‚Ð¾Ð½:\n\n";
  
  selectedExamples.forEach((example, index) => {
    trainingContext += `ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ: ${example.user}\n`;
    trainingContext += `SenterosAI: ${example.assistant}\n\n`;
  });
  
  return trainingContext;
};

// Enhanced system prompt with training examples
const getEnhancedSystemPrompt = (): string => {
  return `${SYSTEM_PROMPT}\n\n${generateTrainingContext()}`;
};

// Get user info from profile for AI context
const getUserProfileContext = (): string => {
  try {
    const userData = {
      username: localStorage.getItem('username') || '',
      bio: localStorage.getItem('userBio') || ''
    };
    
    // Only create context if there's actual data
    if (userData.username || userData.bio) {
      let context = "Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°:\n";
      if (userData.username) context += `Ð˜Ð¼Ñ: ${userData.username}\n`;
      if (userData.bio) context += `Ðž ÑÐµÐ±Ðµ: ${userData.bio}\n`;
      return context;
    }
    return '';
  } catch (error) {
    console.error('Error getting user profile context:', error);
    return '';
  }
};

// Usage tracking functions
const getLimits = () => {
  return {
    requestsPerDay: 100,
    imagesPerDay: 10
  };
};

const getDateKey = () => {
  const now = new Date();
  return `${now.getFullYear()}-${now.getMonth() + 1}-${now.getDate()}`;
};

const incrementDailyUsage = (type: 'requests' | 'images'): number => {
  const dateKey = getDateKey();
  const key = `senterosai_${type}_${dateKey}`;
  const currentUsage = parseInt(localStorage.getItem(key) || '0', 10);
  const newUsage = currentUsage + 1;
  localStorage.setItem(key, newUsage.toString());
  return newUsage;
};

const checkUsageLimits = (type: 'requests' | 'images'): boolean => {
  const dateKey = getDateKey();
  const key = `senterosai_${type}_${dateKey}`;
  const currentUsage = parseInt(localStorage.getItem(key) || '0', 10);
  const limits = getLimits();
  const limit = type === 'requests' ? limits.requestsPerDay : limits.imagesPerDay;
  
  return currentUsage < limit;
};

// Get model based on content (use Mistral Large for images)
const getModelForContent = (messages: ChatMessage[]): string => {
  // Check if there are image attachments in the latest user message
  const lastUserMessage = [...messages].reverse().find(msg => msg.role === 'user');
  
  // Use type guard to safely check for image_url
  const hasImage = lastUserMessage && 
    'image_url' in lastUserMessage && 
    lastUserMessage.image_url !== undefined;
  
  // Always use Mistral Large for image processing
  return hasImage ? 'mistral-large-latest' : 'mistral-small-latest';
};

// Store user profile data from Supabase in localStorage for AI context
export const syncUserProfileToLocalStorage = (userData: any) => {
  if (!userData) return;
  
  if (userData.username) localStorage.setItem('username', userData.username);
  if (userData.bio) localStorage.setItem('userBio', userData.bio);
};

// Type guard to check if a message has an image_url
const hasImageUrl = (message: any): message is ChatMessage & { image_url: string } => {
  return message && typeof message === 'object' && 'image_url' in message && typeof message.image_url === 'string';
};

export const generateChatCompletion = async (messages: ChatMessage[]): Promise<ChatMessage> => {
  try {
    // Check if the daily request limit has been reached
    if (!checkUsageLimits('requests')) {
      return {
        role: 'assistant',
        content: 'Ð’Ñ‹ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð¸ Ð´Ð½ÐµÐ²Ð½Ð¾Ð³Ð¾ Ð»Ð¸Ð¼Ð¸Ñ‚Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² (100). ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¸Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ðº Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñƒ.'
      };
    }
    
    // Check if there are image attachments in the latest user message
    const lastUserMessage = [...messages].reverse().find(msg => msg.role === 'user');
    const hasImage = hasImageUrl(lastUserMessage);
    
    // If there's an image, check image attachment limit
    if (hasImage && !checkUsageLimits('images')) {
      return {
        role: 'assistant',
        content: 'Ð’Ñ‹ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð¸ Ð´Ð½ÐµÐ²Ð½Ð¾Ð³Ð¾ Ð»Ð¸Ð¼Ð¸Ñ‚Ð° Ð¿Ñ€Ð¸ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ (10). ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¸Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ðº Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñƒ.'
      };
    }
    
    // Get user profile context if available
    const userProfileContext = getUserProfileContext();
    
    // Create system message with user context
    const systemContent = userProfileContext 
      ? `${getEnhancedSystemPrompt()}\n\n${userProfileContext}` 
      : getEnhancedSystemPrompt();
    
    // Add system message if not already present
    const messagesWithSystem = messages.some(msg => msg.role === 'system') 
      ? messages 
      : [{ role: 'system', content: systemContent }, ...messages];
    
    // Format messages for API with proper type checking
    const formattedMessages = messagesWithSystem.map(msg => {
      // Use our type guard to safely access image_url property
      if (hasImageUrl(msg)) {
        return {
          role: msg.role,
          content: msg.content,
          image_url: msg.image_url
        };
      }
      return {
        role: msg.role,
        content: msg.content
      };
    });
    
    // Select appropriate model based on content
    const model = getModelForContent(messages);
    
    console.log('Using model:', model, 'Has image:', hasImage);
    
    const response = await fetch('https://api.mistral.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${getApiKey()}`,
      },
      body: JSON.stringify({
        model: model,
        messages: formattedMessages,
        temperature: 0.7,
        max_tokens: 2048,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      console.error('Mistral API error:', errorData);
      throw new Error(errorData.error?.message || 'Failed to generate completion');
    }

    // Increment the request counter after successful API call
    incrementDailyUsage('requests');
    
    // If image was used, increment the image counter too
    if (hasImage) {
      incrementDailyUsage('images');
    }

    const data = await response.json();
    
    if (!data.choices || data.choices.length === 0) {
      throw new Error('No response data received from API');
    }
    
    return {
      role: 'assistant',
      content: data.choices[0].message.content
    };
  } catch (error) {
    console.error('Error generating chat completion:', error);
    throw error;
  }
};

export const generateChatTitle = async (messages: ChatMessage[]): Promise<string> => {
  try {
    // Keep only the first few messages to avoid token limits
    const limitedMessages = messages.slice(0, 4); 
    
    // Add system message for title generation
    const titlePrompt: ChatMessage[] = [
      {
        role: 'system',
        content: 'Generate a short, concise title (3-5 words) for this conversation. Return ONLY the title text without quotes or explanation.'
      },
      ...limitedMessages.map(msg => ({
        role: msg.role,
        content: msg.content
      }))
    ];
    
    const response = await fetch('https://api.mistral.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${getApiKey()}`,
      },
      body: JSON.stringify({
        model: 'mistral-small-latest',
        messages: titlePrompt,
        max_tokens: 30,
        temperature: 0.5,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(errorData.error?.message || 'Failed to generate title');
    }

    const data = await response.json();
    let title = data.choices[0].message.content.trim();
    
    // Remove quotes if the AI added them
    if ((title.startsWith('"') && title.endsWith('"')) || 
        (title.startsWith("'") && title.endsWith("'"))) {
      title = title.substring(1, title.length - 1);
    }
    
    return title;
  } catch (error) {
    console.error('Error generating chat title:', error);
    return '';
  }
};

export const simulateStreamingResponse = (
  text: string,
  onChunk: (chunk: string) => void,
  onComplete: () => void
): (() => void) => {
  let isCancelled = false;
  let currentIndex = 0;
  const textLength = text.length;
  
  // Create chunks of text for realistic streaming
  const simulateTokenStream = () => {
    if (isCancelled) return;
    
    // Calculate a variable chunk size between 1-3 characters for more realistic streaming
    const chunkSize = Math.floor(Math.random() * 3) + 1;
    const endIndex = Math.min(currentIndex + chunkSize, textLength);
    
    if (currentIndex < textLength) {
      const chunk = text.substring(currentIndex, endIndex);
      onChunk(chunk);
      currentIndex = endIndex;
      
      // Randomly vary the typing speed between 10-40ms for more natural typing
      const nextDelay = Math.floor(Math.random() * 30) + 10;
      setTimeout(simulateTokenStream, nextDelay);
    } else {
      onComplete();
    }
  };
  
  // Start streaming with a small initial delay
  setTimeout(simulateTokenStream, 100);
  
  // Return cancel function
  return () => {
    isCancelled = true;
  };
};
